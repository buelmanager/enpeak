---
title: EnPeak
emoji: ğŸ—£ï¸
colorFrom: blue
colorTo: green
sdk: docker
pinned: false
---

# EnPeak

AI ê¸°ë°˜ ì˜ì–´ íšŒí™” í•™ìŠµ PWA ì›¹ì•±. ìŒì„± ì¸ì‹ê³¼ AI íŠœí„°ë¥¼ í†µí•´ ì‹¤ì‹œê°„ ì˜ì–´ íšŒí™” ì—°ìŠµì„ ì œê³µí•œë‹¤.

## Screenshots

<p align="center">
  <img src="images/1.png" width="200" alt="Home" />
  <img src="images/2.png" width="200" alt="Free Conversation" />
  <img src="images/3.png" width="200" alt="Voice Recording" />
</p>
<p align="center">
  <img src="images/4.png" width="200" alt="Daily Expression" />
  <img src="images/5.png" width="200" alt="Vocabulary" />
  <img src="images/6.png" width="200" alt="Community" />
</p>

| Screen | Description |
|--------|-------------|
| Home | ëŒ€ì‹œë³´ë“œ, í•™ìŠµ í†µê³„, ì˜¤ëŠ˜ì˜ í‘œí˜„/ë‹¨ì–´ ì—°ìŠµ ì§„ì…ì  |
| Free Conversation | AIì™€ ì‹¤ì‹œê°„ ì˜ì–´ ëŒ€í™”, ì¶”ì²œ í‘œí˜„, í•œêµ­ì–´ ë²ˆì—­ ì œê³µ |
| Voice Recording | Web Speech API ê¸°ë°˜ ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ |
| Daily Expression | ë§¤ì¼ ìƒˆë¡œìš´ ì˜ì–´ í‘œí˜„ í•™ìŠµ, TTS ë°œìŒ ì§€ì› |
| Vocabulary | A1-C2 ë ˆë²¨ë³„ í”Œë˜ì‹œì¹´ë“œ, ëœ»/ë‹¨ì–´ ê°€ë¦¬ê¸° ëª¨ë“œ |
| Community | ì‚¬ìš©ì ìƒì„± ë¡¤í”Œë ˆì´ ì‹œë‚˜ë¦¬ì˜¤ ê³µìœ  |

---

## Tech Stack

### Frontend

| Category | Technology | Version | Description |
|----------|------------|---------|-------------|
| Framework | Next.js | 14.1.0 | App Router ê¸°ë°˜, RSC(React Server Components) ì§€ì› |
| Language | TypeScript | 5.3.3 | ì •ì  íƒ€ì… ê²€ì‚¬, ì¸í„°í˜ì´ìŠ¤ ì •ì˜ |
| Styling | Tailwind CSS | 3.4.1 | Utility-first CSS, JIT ì»´íŒŒì¼ëŸ¬ |
| UI State | React | 18.2.0 | useState, useEffect, useCallback í›… ê¸°ë°˜ |
| HTTP Client | Axios | 1.6.5 | ì¸í„°ì…‰í„°, ì—ëŸ¬ í•¸ë“¤ë§, íƒ€ì… ì§€ì› |
| Backend Service | Firebase SDK | 12.8.0 | Firestore, Authentication |
| Build Tool | Turbopack | - | Next.js 14 ê¸°ë³¸ ë²ˆë“¤ëŸ¬ (dev mode) |

**Frontend ì•„í‚¤í…ì²˜ íŠ¹ì§•:**

```
src/
â”œâ”€â”€ app/                    # App Router (file-based routing)
â”‚   â”œâ”€â”€ layout.tsx          # Root layout (providers, global styles)
â”‚   â”œâ”€â”€ page.tsx            # Home page (/)
â”‚   â”œâ”€â”€ chat/
â”‚   â”‚   â””â”€â”€ page.tsx        # Free conversation (/chat)
â”‚   â”œâ”€â”€ roleplay/
â”‚   â”‚   â”œâ”€â”€ page.tsx        # Scenario list (/roleplay)
â”‚   â”‚   â””â”€â”€ [id]/
â”‚   â”‚       â””â”€â”€ page.tsx    # Dynamic route (/roleplay/:id)
â”‚   â””â”€â”€ vocabulary/
â”‚       â””â”€â”€ page.tsx        # Vocabulary practice (/vocabulary)
â”œâ”€â”€ components/             # Reusable UI components
â”‚   â”œâ”€â”€ ChatWindow.tsx      # Message list, scroll management
â”‚   â”œâ”€â”€ VoiceRecorder.tsx   # Web Speech API wrapper
â”‚   â””â”€â”€ MessageBubble.tsx   # AI/User message styling
â”œâ”€â”€ hooks/                  # Custom React hooks
â”‚   â”œâ”€â”€ useSpeechRecognition.ts  # STT hook
â”‚   â”œâ”€â”€ useSpeechSynthesis.ts    # TTS hook
â”‚   â””â”€â”€ useLocalStorage.ts       # Persistent state
â””â”€â”€ lib/
    â”œâ”€â”€ api.ts              # Axios instance, API functions
    â””â”€â”€ utils.ts            # Helper functions
```

**í•µì‹¬ ê¸°ìˆ  êµ¬í˜„:**

1. **Web Speech API Integration**
   - `SpeechRecognition`: ë¸Œë¼ìš°ì € ë‚´ì¥ STT, ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹
   - `SpeechSynthesis`: ë¸Œë¼ìš°ì € ë‚´ì¥ TTS, ë‹¤ì–‘í•œ ìŒì„± ì„ íƒ
   - Fallback: ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¸Œë¼ìš°ì €ì—ì„œ ë°±ì—”ë“œ API ì‚¬ìš©

2. **PWA (Progressive Web App)**
   - `manifest.json`: ì•± ì•„ì´ì½˜, í…Œë§ˆ ìƒ‰ìƒ, í‘œì‹œ ëª¨ë“œ ì •ì˜
   - Service Worker: ì˜¤í”„ë¼ì¸ ìºì‹± (Next.js ê¸°ë³¸ ì§€ì›)
   - Add to Home Screen: ëª¨ë°”ì¼ ì•±ì²˜ëŸ¼ ì„¤ì¹˜ ê°€ëŠ¥

3. **State Management**
   - Local State: `useState` ê¸°ë°˜ ì»´í¬ë„ŒíŠ¸ ìƒíƒœ
   - Persistent State: `localStorage` ê¸°ë°˜ ì„¤ì • ì €ì¥
   - No Redux/Zustand: ë³µì¡ë„ ìµœì†Œí™”, ë‹¨ìˆœí•œ ìƒíƒœ êµ¬ì¡°

---

### Backend

| Category | Technology | Version | Description |
|----------|------------|---------|-------------|
| Framework | FastAPI | 0.109.0 | ë¹„ë™ê¸° ì§€ì›, OpenAPI ìë™ ë¬¸ì„œí™” |
| Language | Python | 3.11+ | íƒ€ì… íŒíŠ¸, async/await ë„¤ì´í‹°ë¸Œ ì§€ì› |
| Validation | Pydantic | 2.6.0 | ëŸ°íƒ€ì„ ë°ì´í„° ê²€ì¦, JSON ìŠ¤í‚¤ë§ˆ ìƒì„± |
| Vector DB | ChromaDB | 0.4.0 | ì„ë² ë”© ì €ì¥, ìœ ì‚¬ë„ ê²€ìƒ‰ |
| Embedding | sentence-transformers | 2.2.0+ | ë‹¤êµ­ì–´ í…ìŠ¤íŠ¸ ì„ë² ë”© |
| TTS | gTTS | 2.5.0 | Google TTS API ë˜í¼ |
| Firebase | firebase-admin | 6.4.0+ | Firestore ì„œë²„ SDK |
| Server | Uvicorn | 0.27.0+ | ASGI ì„œë²„, HTTP/2 ì§€ì› |

**Backend ì•„í‚¤í…ì²˜ íŠ¹ì§•:**

```
backend/
â”œâ”€â”€ main.py                 # FastAPI app, lifespan, middleware
â”œâ”€â”€ api/                    # API ë¼ìš°í„° ëª¨ë“ˆ
â”‚   â”œâ”€â”€ chat.py             # POST /api/chat
â”‚   â”œâ”€â”€ roleplay.py         # /api/roleplay/*
â”‚   â”œâ”€â”€ speech.py           # /api/speech/stt, /api/speech/tts
â”‚   â”œâ”€â”€ feedback.py         # POST /api/feedback/grammar
â”‚   â”œâ”€â”€ vocabulary.py       # /api/vocabulary/*
â”‚   â”œâ”€â”€ rag.py              # /api/rag/*
â”‚   â””â”€â”€ community.py        # /api/community/*
â”œâ”€â”€ core/                   # ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
â”‚   â”œâ”€â”€ llm.py              # LLM í”„ë¡œë°”ì´ë” ì¶”ìƒí™”
â”‚   â”œâ”€â”€ prompts.py          # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
â”‚   â””â”€â”€ firebase.py         # Firestore í´ë¼ì´ì–¸íŠ¸
â””â”€â”€ scenarios/
    â””â”€â”€ scenario_engine.py  # ë¡¤í”Œë ˆì´ ìƒíƒœ ë¨¸ì‹ 
```

**í•µì‹¬ ê¸°ìˆ  êµ¬í˜„:**

1. **LLM Manager (Strategy Pattern)**
   ```python
   class LLMManager:
       def __init__(self, groq_api_key=None, mistral_api_key=None):
           # Provider ìš°ì„ ìˆœìœ„: Groq > Mistral
           if groq_api_key:
               self.provider = "groq"
               self.client = GroqClient(api_key=groq_api_key)
           elif mistral_api_key:
               self.provider = "mistral"
               self.client = MistralClient(api_key=mistral_api_key)

       async def generate(self, messages: list[dict], **kwargs) -> str:
           # ë™ì¼í•œ ì¸í„°í˜ì´ìŠ¤ë¡œ ë‹¤ë¥¸ í”„ë¡œë°”ì´ë” í˜¸ì¶œ
           return await self.client.chat(messages, **kwargs)
   ```

2. **RAG Pipeline**
   ```
   Query â†’ Embedding â†’ ChromaDB Search â†’ Context Retrieval â†’ LLM + Context â†’ Response
   ```
   - Embedding Model: `intfloat/multilingual-e5-base` (ë‹¤êµ­ì–´ ì§€ì›)
   - Vector Store: ChromaDB (Persistent mode, SQLite ë°±ì—”ë“œ)
   - Search: Cosine similarity, top-k retrieval

3. **Async Request Handling**
   ```python
   @router.post("/chat")
   async def chat(request: ChatRequest):
       # ë¹„ë™ê¸° LLM í˜¸ì¶œ
       response = await llm_manager.generate(messages)
       # ë¹„ë™ê¸° ë¬¸ë²• í”¼ë“œë°± (optional)
       feedback = await grammar_checker.analyze(request.message)
       return ChatResponse(response=response, feedback=feedback)
   ```

---

### AI/LLM

| Provider | Model | Context | Speed | Usage |
|----------|-------|---------|-------|-------|
| Groq | llama-3.1-70b-versatile | 128K | ~500 tok/s | Primary LLM (ëŒ€í™” ìƒì„±) |
| Mistral | open-mixtral-8x7b | 32K | ~200 tok/s | Fallback LLM |
| Groq | whisper-large-v3 | - | Real-time | Backend STT (fallback) |

**LLM ì„ íƒ ê¸°ì¤€:**
- **Groq**: ì´ˆì €ì§€ì—° (< 1ì´ˆ ì‘ë‹µ), ë¬´ë£Œ í‹°ì–´ (ì¼ì¼ í•œë„), í•œêµ­ì–´ ì„±ëŠ¥ ìš°ìˆ˜
- **Mistral**: ì•ˆì •ì  fallback, ìœ ëŸ½ GDPR ì¤€ìˆ˜, ë‹¤êµ­ì–´ ì§€ì›

**í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§:**

```python
TUTOR_SYSTEM_PROMPT = """
You are an English conversation tutor for Korean speakers.

Guidelines:
1. Respond in English, keep it natural and conversational
2. If the user makes grammar mistakes, gently correct them
3. Provide Korean translation in parentheses for difficult words
4. Suggest alternative expressions when appropriate
5. Keep responses concise (2-3 sentences max)

Current context: {context}
User's English level: {level}
"""
```

---

### Infrastructure

| Service | Platform | Tier | Description |
|---------|----------|------|-------------|
| Frontend Hosting | Firebase Hosting | Spark (Free) | CDN, SSL, ìë™ ë°°í¬ |
| Backend Hosting | HuggingFace Spaces | Free | Docker ì»¨í…Œì´ë„ˆ, GPU ì˜µì…˜ |
| Database | Firebase Firestore | Spark (Free) | NoSQL, ì‹¤ì‹œê°„ ë™ê¸°í™” |
| Vector Store | ChromaDB | Self-hosted | Docker ë‚´ Persistent ì €ì¥ |

**ë°°í¬ ì•„í‚¤í…ì²˜:**

```
                    +------------------+
                    |   Firebase CDN   |
                    |  (Global Edge)   |
                    +--------+---------+
                             |
              +--------------+--------------+
              |                             |
    +---------v---------+         +---------v---------+
    |  Firebase Hosting |         |   HuggingFace     |
    |  (Static Assets)  |         |   Spaces (API)    |
    |  - Next.js build  |         |   - FastAPI       |
    |  - PWA manifest   |         |   - ChromaDB      |
    +-------------------+         |   - LLM Client    |
                                  +---------+---------+
                                            |
                              +-------------+-------------+
                              |                           |
                    +---------v---------+       +---------v---------+
                    |   Groq Cloud      |       |  Firebase         |
                    |   (LLM API)       |       |  Firestore        |
                    +-------------------+       +-------------------+
```

---

## Architecture

### System Architecture

```
+-------------------------------------------------------------------------+
|                              Client (PWA)                               |
|  +------------------+  +------------------+  +------------------------+  |
|  |   Next.js 14     |  |  Web Speech API  |  |    Firebase SDK        |  |
|  |   App Router     |  |  - Recognition   |  |    - Firestore         |  |
|  |   - SSR/SSG      |  |  - Synthesis     |  |    - Auth              |  |
|  +--------+---------+  +--------+---------+  +-----------+------------+  |
+-----------|---------------------|--------------------------|-------------+
            |                     |                          |
            | HTTPS               | (Browser API)            | WebSocket
            |                     |                          |
+-----------|---------------------|--------------------------|-------------+
|           v                     v                          v             |
|  +------------------------------------------------------------------+   |
|  |                        FastAPI Backend                           |   |
|  |  +--------------------+  +--------------------+  +--------------+|   |
|  |  |   API Layer        |  |   Core Services    |  |   Data Layer ||   |
|  |  |   - /api/chat      |  |   - LLMManager     |  |   - ChromaDB ||   |
|  |  |   - /api/roleplay  |  |   - RAGPipeline    |  |   - Firestore||   |
|  |  |   - /api/vocabulary|  |   - ScenarioEngine |  |   - Cache    ||   |
|  |  |   - /api/rag       |  |   - GrammarChecker |  |              ||   |
|  |  +--------------------+  +--------------------+  +--------------+|   |
|  +------------------------------------------------------------------+   |
|                              HuggingFace Spaces                         |
+-------------------------------------------------------------------------+
            |                          |
            v                          v
+-------------------+        +-------------------+
|   Groq Cloud      |        |   Mistral Cloud   |
|   - LLaMA 3.1 70B |        |   - Mixtral 8x7B  |
|   - Whisper v3    |        |                   |
+-------------------+        +-------------------+
```

### Data Flow

```
[User Voice Input]
        |
        v
+------------------+
| Web Speech API   |  <-- Browser-native STT (free, fast)
| (Recognition)    |
+--------+---------+
         |
         | Text
         v
+------------------+
| Frontend         |
| - Input validation
| - Session management
+--------+---------+
         |
         | POST /api/chat
         v
+------------------+
| FastAPI Backend  |
+--------+---------+
         |
    +----+----+
    |         |
    v         v
+-------+  +-------+
| RAG   |  | LLM   |
| Search|  | Call  |
+---+---+  +---+---+
    |          |
    +----+-----+
         |
         v
+------------------+
| Response         |
| - AI message     |
| - Grammar feedback
| - Suggestions    |
+--------+---------+
         |
         v
+------------------+
| Web Speech API   |  <-- Browser-native TTS (free, fast)
| (Synthesis)      |
+------------------+
         |
         v
[Audio Output to User]
```

---

## Project Structure

```
enpeak/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                     # FastAPI entry, lifespan, CORS middleware
â”‚   â”œâ”€â”€ requirements.txt            # Python dependencies
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ chat.py                 # Free conversation endpoint
â”‚   â”‚   â”‚                           # - Message history management
â”‚   â”‚   â”‚                           # - Context injection from RAG
â”‚   â”‚   â”œâ”€â”€ roleplay.py             # Scenario-based roleplay
â”‚   â”‚   â”‚                           # - Session state machine
â”‚   â”‚   â”‚                           # - Stage progression
â”‚   â”‚   â”œâ”€â”€ speech.py               # STT/TTS fallback endpoints
â”‚   â”‚   â”‚                           # - Groq Whisper for STT
â”‚   â”‚   â”‚                           # - gTTS for TTS
â”‚   â”‚   â”œâ”€â”€ feedback.py             # Grammar correction
â”‚   â”‚   â”‚                           # - LLM-based analysis
â”‚   â”‚   â”‚                           # - Suggestion generation
â”‚   â”‚   â”œâ”€â”€ vocabulary.py           # Word learning API
â”‚   â”‚   â”‚                           # - CEFR level filtering
â”‚   â”‚   â”‚                           # - Expansion to idioms/sentences
â”‚   â”‚   â”œâ”€â”€ rag.py                  # RAG search API
â”‚   â”‚   â”‚                           # - Semantic search
â”‚   â”‚   â”‚                           # - Multi-language support
â”‚   â”‚   â””â”€â”€ community.py            # User-generated content
â”‚   â”‚                               # - Firestore CRUD
â”‚   â”‚                               # - Content moderation
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ llm.py                  # LLM provider abstraction
â”‚   â”‚   â”‚                           # - Groq/Mistral Strategy pattern
â”‚   â”‚   â”‚                           # - Retry logic, error handling
â”‚   â”‚   â”œâ”€â”€ prompts.py              # System prompt templates
â”‚   â”‚   â”‚                           # - Tutor persona
â”‚   â”‚   â”‚                           # - Grammar checker
â”‚   â”‚   â”‚                           # - Scenario-specific prompts
â”‚   â”‚   â””â”€â”€ firebase.py             # Firestore client singleton
â”‚   â”‚                               # - Connection pooling
â”‚   â”‚                               # - Collection references
â”‚   â””â”€â”€ scenarios/
â”‚       â””â”€â”€ scenario_engine.py      # Roleplay state machine
â”‚                                   # - Stage transitions
â”‚                                   # - Completion detection
â”‚                                   # - Report generation
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ next.config.js              # Next.js configuration
â”‚   â”‚                               # - API rewrites
â”‚   â”‚                               # - Image optimization
â”‚   â”œâ”€â”€ tailwind.config.js          # Tailwind configuration
â”‚   â”‚                               # - Custom colors
â”‚   â”‚                               # - Font family
â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â”œâ”€â”€ manifest.json           # PWA manifest
â”‚   â”‚   â”œâ”€â”€ icons/                  # App icons (192x192, 512x512)
â”‚   â”‚   â””â”€â”€ favicon.ico
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ app/
â”‚       â”‚   â”œâ”€â”€ layout.tsx          # Root layout
â”‚       â”‚   â”‚                       # - Global providers
â”‚       â”‚   â”‚                       # - Meta tags
â”‚       â”‚   â”œâ”€â”€ page.tsx            # Home dashboard
â”‚       â”‚   â”œâ”€â”€ chat/
â”‚       â”‚   â”‚   â””â”€â”€ page.tsx        # Free conversation
â”‚       â”‚   â”œâ”€â”€ roleplay/
â”‚       â”‚   â”‚   â”œâ”€â”€ page.tsx        # Scenario list
â”‚       â”‚   â”‚   â””â”€â”€ [id]/
â”‚       â”‚   â”‚       â””â”€â”€ page.tsx    # Roleplay session
â”‚       â”‚   â”œâ”€â”€ vocabulary/
â”‚       â”‚   â”‚   â””â”€â”€ page.tsx        # Vocabulary practice
â”‚       â”‚   â””â”€â”€ conversations/
â”‚       â”‚       â””â”€â”€ page.tsx        # Community scenarios
â”‚       â”œâ”€â”€ components/
â”‚       â”‚   â”œâ”€â”€ ChatWindow.tsx      # Message container
â”‚       â”‚   â”‚                       # - Auto-scroll
â”‚       â”‚   â”‚                       # - Loading states
â”‚       â”‚   â”œâ”€â”€ VoiceRecorder.tsx   # Speech input
â”‚       â”‚   â”‚                       # - Recording indicator
â”‚       â”‚   â”‚                       # - Permission handling
â”‚       â”‚   â”œâ”€â”€ MessageBubble.tsx   # Single message
â”‚       â”‚   â”‚                       # - AI/User styling
â”‚       â”‚   â”‚                       # - Translation toggle
â”‚       â”‚   â””â”€â”€ LevelSelector.tsx   # CEFR level picker
â”‚       â”œâ”€â”€ hooks/
â”‚       â”‚   â”œâ”€â”€ useSpeechRecognition.ts
â”‚       â”‚   â”œâ”€â”€ useSpeechSynthesis.ts
â”‚       â”‚   â””â”€â”€ useLocalStorage.ts
â”‚       â””â”€â”€ lib/
â”‚           â”œâ”€â”€ api.ts              # API client
â”‚           â””â”€â”€ utils.ts            # Helpers
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ scenarios/                  # 14 roleplay scenarios (JSON)
â”‚   â”‚   â”œâ”€â”€ cafe_order.json
â”‚   â”‚   â”œâ”€â”€ hotel_checkin.json
â”‚   â”‚   â”œâ”€â”€ job_interview.json
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ rag_chunks/                 # RAG data (5,375 chunks)
â”‚       â”œâ”€â”€ all_chunks.json         # Merged data
â”‚       â”œâ”€â”€ vocabulary_chunks.json  # 2,661 words
â”‚       â”œâ”€â”€ dialogsum_chunks.json   # 1,500 dialogues
â”‚       â”œâ”€â”€ expressions_chunks.json # 720 expressions
â”‚       â””â”€â”€ patterns_chunks.json    # Grammar patterns
â”‚
â”œâ”€â”€ vectordb/                       # ChromaDB persistent storage
â”‚   â””â”€â”€ chroma.sqlite3              # Vector index (~6MB)
â”‚
â”œâ”€â”€ scripts/                        # Data processing
â”‚   â”œâ”€â”€ download_datasets.py        # Fetch open datasets
â”‚   â”œâ”€â”€ expand_vocabulary.py        # Generate A1-C2 words
â”‚   â”œâ”€â”€ generate_expressions.py     # Create expressions
â”‚   â””â”€â”€ index_to_chromadb.py        # Build vector index
â”‚
â”œâ”€â”€ images/                         # App screenshots
â”‚   â”œâ”€â”€ 1.png                       # Home
â”‚   â”œâ”€â”€ 2.png                       # Chat
â”‚   â”œâ”€â”€ 3.png                       # Recording
â”‚   â”œâ”€â”€ 4.png                       # Expression
â”‚   â”œâ”€â”€ 5.png                       # Vocabulary
â”‚   â””â”€â”€ 6.png                       # Community
â”‚
â”œâ”€â”€ Dockerfile                      # Backend container
â”œâ”€â”€ .env.example                    # Environment template
â””â”€â”€ README.md
```

---

## Design Patterns

### Backend Patterns

| Pattern | Location | Implementation | Purpose |
|---------|----------|----------------|---------|
| **Strategy** | `core/llm.py` | `LLMManager` class with pluggable providers | LLM í”„ë¡œë°”ì´ë” êµì²´ (Groq/Mistral) without code change |
| **Singleton** | `main.py` | `AppState` class, `app_state` instance | ì•± ì „ì—­ ìƒíƒœ (LLM client, embeddings) ê³µìœ  |
| **Repository** | `core/firebase.py` | `CommunityStore` class | Firestore ì ‘ê·¼ ì¶”ìƒí™”, í…ŒìŠ¤íŠ¸ ìš©ì´ì„± |
| **State Machine** | `scenarios/scenario_engine.py` | `ScenarioSession` class | ë¡¤í”Œë ˆì´ ë‹¨ê³„ ê´€ë¦¬ (greeting â†’ order â†’ payment â†’ complete) |
| **Factory** | `api/roleplay.py` | `create_session()` function | ì‹œë‚˜ë¦¬ì˜¤ íƒ€ì…ë³„ ì„¸ì…˜ ê°ì²´ ìƒì„± |
| **Dependency Injection** | All routers | FastAPI `Depends()` | Request-scoped ì˜ì¡´ì„± (DB connection, auth) |

**Strategy Pattern Example (LLM Manager):**

```python
# core/llm.py
class LLMProvider(Protocol):
    async def chat(self, messages: list[dict], **kwargs) -> str: ...

class GroqProvider:
    def __init__(self, api_key: str):
        self.client = Groq(api_key=api_key)

    async def chat(self, messages, model="llama-3.1-70b-versatile", **kwargs):
        response = await self.client.chat.completions.create(
            model=model, messages=messages, **kwargs
        )
        return response.choices[0].message.content

class MistralProvider:
    def __init__(self, api_key: str):
        self.client = MistralClient(api_key=api_key)

    async def chat(self, messages, model="open-mixtral-8x7b", **kwargs):
        response = await self.client.chat(model=model, messages=messages)
        return response.choices[0].message.content

class LLMManager:
    def __init__(self, groq_key=None, mistral_key=None):
        if groq_key:
            self.provider = GroqProvider(groq_key)
        elif mistral_key:
            self.provider = MistralProvider(mistral_key)
        else:
            raise ValueError("No LLM API key provided")

    async def generate(self, messages, **kwargs):
        return await self.provider.chat(messages, **kwargs)
```

### Frontend Patterns

| Pattern | Location | Implementation | Purpose |
|---------|----------|----------------|---------|
| **Container/Presenter** | `app/*/page.tsx` + `components/` | Page handles logic, Component handles UI | ê´€ì‹¬ì‚¬ ë¶„ë¦¬, í…ŒìŠ¤íŠ¸ ìš©ì´ì„± |
| **Custom Hooks** | `hooks/` | `useSpeechRecognition`, `useSpeechSynthesis` | ìƒíƒœ ë¡œì§ ì¬ì‚¬ìš©, ì»´í¬ë„ŒíŠ¸ ë‹¨ìˆœí™” |
| **Compound Components** | `components/ChatWindow.tsx` | `ChatWindow`, `MessageBubble`, `InputArea` | ê´€ë ¨ ì»´í¬ë„ŒíŠ¸ ê·¸ë£¹í™”, ì¼ê´€ëœ API |
| **Render Props** | `components/VoiceRecorder.tsx` | `children` as function | ë…¹ìŒ ìƒíƒœ ì»¤ìŠ¤í…€ ë Œë”ë§ |

**Custom Hook Example (Speech Recognition):**

```typescript
// hooks/useSpeechRecognition.ts
export function useSpeechRecognition() {
  const [transcript, setTranscript] = useState("");
  const [isListening, setIsListening] = useState(false);
  const recognitionRef = useRef<SpeechRecognition | null>(null);

  useEffect(() => {
    if (typeof window === "undefined") return;

    const SpeechRecognition =
      window.SpeechRecognition || window.webkitSpeechRecognition;

    if (!SpeechRecognition) return;

    recognitionRef.current = new SpeechRecognition();
    recognitionRef.current.continuous = true;
    recognitionRef.current.interimResults = true;
    recognitionRef.current.lang = "en-US";

    recognitionRef.current.onresult = (event) => {
      const current = event.resultIndex;
      const result = event.results[current];
      setTranscript(result[0].transcript);
    };

    return () => recognitionRef.current?.stop();
  }, []);

  const startListening = useCallback(() => {
    recognitionRef.current?.start();
    setIsListening(true);
  }, []);

  const stopListening = useCallback(() => {
    recognitionRef.current?.stop();
    setIsListening(false);
  }, []);

  return { transcript, isListening, startListening, stopListening };
}
```

---

## API Specification

### Core Endpoints

| Endpoint | Method | Auth | Rate Limit | Description |
|----------|--------|------|------------|-------------|
| `/api/health` | GET | No | - | Health check, version info |
| `/api/chat` | POST | No | 60/min | Free conversation with AI |
| `/api/speech/stt` | POST | No | 30/min | Speech-to-text (fallback) |
| `/api/speech/tts` | POST | No | 60/min | Text-to-speech |
| `/api/feedback/grammar` | POST | No | 30/min | Grammar correction |

### Roleplay Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `GET /api/roleplay/scenarios` | GET | List all 14 scenarios with metadata |
| `POST /api/roleplay/start` | POST | Initialize session, return first AI message |
| `POST /api/roleplay/turn` | POST | Process user turn, return AI response + feedback |
| `POST /api/roleplay/end` | POST | End session, generate performance report |

### RAG Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `POST /api/rag/search` | POST | Semantic search across all data types |
| `GET /api/rag/related/{word}` | GET | Get related expressions, idioms, sentences |
| `GET /api/rag/stats` | GET | Data statistics by type and level |

### Vocabulary Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `GET /api/vocabulary/list` | GET | Get words by CEFR level (A1-C2) |
| `POST /api/vocabulary/add` | POST | Add word with AI validation |
| `POST /api/vocabulary/expand` | POST | Expand word to idioms/sentences |
| `DELETE /api/vocabulary/remove/{word}` | DELETE | Remove word from list |

### Request/Response Examples

**POST /api/chat**

```json
// Request
{
  "message": "I want to practice ordering coffee",
  "session_id": "550e8400-e29b-41d4-a716-446655440000",
  "context": [
    {"role": "user", "content": "Hello"},
    {"role": "assistant", "content": "Hi! How can I help you today?"}
  ],
  "settings": {
    "level": "B1",
    "include_translation": true,
    "include_suggestions": true
  }
}

// Response
{
  "response": "Sure! Let's practice ordering coffee. Imagine you're at a cafe. I'll be the barista. What would you like to order?",
  "translation": "ì¢‹ì•„ìš”! ì»¤í”¼ ì£¼ë¬¸ ì—°ìŠµì„ í•´ë´…ì‹œë‹¤. ì¹´í˜ì— ìˆë‹¤ê³  ìƒìƒí•´ë³´ì„¸ìš”. ì œê°€ ë°”ë¦¬ìŠ¤íƒ€ê°€ ë ê²Œìš”. ë¬´ì—‡ì„ ì£¼ë¬¸í•˜ì‹œê² ì–´ìš”?",
  "suggestions": [
    "I'd like a latte, please.",
    "Can I get a medium cappuccino?",
    "What do you recommend?"
  ],
  "feedback": null
}
```

**POST /api/rag/search**

```json
// Request
{
  "query": "coffee order",
  "n_results": 5,
  "filters": {
    "type": ["expression", "dialogue"],
    "category": "cafe",
    "level": ["A2", "B1"]
  }
}

// Response
{
  "results": [
    {
      "id": "expr_cafe_001",
      "content": "I'd like a latte, please.",
      "type": "expression",
      "category": "cafe",
      "level": "A2",
      "metadata": {
        "korean": "ë¼ë–¼ ì£¼ì„¸ìš”.",
        "context": "Ordering at a coffee shop"
      },
      "score": 0.92
    },
    {
      "id": "dial_cafe_015",
      "content": "Customer: Can I get a medium cappuccino?\nBarista: Sure! Would you like any flavoring with that?",
      "type": "dialogue",
      "category": "cafe",
      "level": "B1",
      "score": 0.87
    }
  ],
  "total": 2,
  "query_time_ms": 45
}
```

**POST /api/roleplay/start**

```json
// Request
{
  "scenario_id": "cafe_order",
  "user_level": "B1"
}

// Response
{
  "session_id": "rp_550e8400-e29b-41d4-a716-446655440000",
  "scenario": {
    "id": "cafe_order",
    "title": "Ordering at a Cafe",
    "title_ko": "ì¹´í˜ ì£¼ë¬¸í•˜ê¸°",
    "roles": {
      "ai": "Barista",
      "user": "Customer"
    }
  },
  "current_stage": {
    "stage": 1,
    "name": "Greeting",
    "learning_tip": "Use 'I'd like...' to order politely"
  },
  "ai_message": {
    "content": "Hi! Welcome to Sunny Cafe. What can I get for you today?",
    "translation": "ì•ˆë…•í•˜ì„¸ìš”! ì¨ë‹ˆ ì¹´í˜ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤. ì˜¤ëŠ˜ ë¬´ì—‡ì„ ë“œë¦´ê¹Œìš”?"
  },
  "suggested_responses": [
    "Hi! I'd like a latte, please.",
    "Hello! Can I see the menu?",
    "Good morning! What do you recommend?"
  ]
}
```

---

## Configuration

### Environment Variables

```bash
# ===================
# LLM API Keys
# ===================
# At least one required. Groq is preferred (faster, free tier).
GROQ_API_KEY=gsk_xxxxxxxxxxxxxxxxxxxxxxxxxxxx
MISTRAL_API_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# ===================
# Firebase Configuration
# ===================
# Required for community features (Firestore)
# JSON string of service account credentials
FIREBASE_CREDENTIALS={"type":"service_account","project_id":"...","private_key":"..."}

# ===================
# App Settings
# ===================
# Server configuration
PORT=7860                    # HuggingFace Spaces default
HOST=0.0.0.0                 # Listen on all interfaces
DEBUG=false                  # Enable debug logging

# ===================
# CORS Configuration
# ===================
# Comma-separated list of allowed origins
ALLOWED_ORIGINS=https://your-app.web.app,http://localhost:3000

# ===================
# RAG Configuration
# ===================
# Embedding model for semantic search
EMBEDDINGS_MODEL_NAME=intfloat/multilingual-e5-base

# ChromaDB storage path (relative to backend/)
CHROMADB_PATH=./vectordb

# ===================
# Optional Settings
# ===================
# Rate limiting (requests per minute)
RATE_LIMIT_CHAT=60
RATE_LIMIT_SPEECH=30

# Cache TTL (seconds)
CACHE_TTL=3600
```

### .env.example

```bash
# Copy this file to .env and fill in the values
cp .env.example .env

# Required
GROQ_API_KEY=your_groq_api_key_here

# Optional (if using Firestore)
FIREBASE_CREDENTIALS={"type":"service_account",...}

# Development
DEBUG=true
ALLOWED_ORIGINS=http://localhost:3000
```

---

## Development Setup

### Requirements

| Tool | Version | Purpose |
|------|---------|---------|
| Node.js | 18+ | Frontend runtime |
| Python | 3.11+ | Backend runtime |
| Docker | 20+ | Container deployment (optional) |
| Git | 2.30+ | Version control |

### Backend Setup

```bash
# 1. Clone repository
git clone https://github.com/your-username/enpeak.git
cd enpeak

# 2. Create virtual environment
cd backend
python -m venv venv

# 3. Activate virtual environment
# macOS/Linux:
source venv/bin/activate
# Windows:
venv\Scripts\activate

# 4. Install dependencies
pip install -r requirements.txt

# 5. Set environment variables
cp .env.example .env
# Edit .env with your API keys

# 6. Initialize vector database (first time only)
python scripts/index_to_chromadb.py

# 7. Run development server
python -m uvicorn main:app --reload --port 7860

# Server running at http://localhost:7860
# API docs at http://localhost:7860/docs
```

### Frontend Setup

```bash
# 1. Navigate to frontend directory
cd frontend

# 2. Install dependencies
npm install

# 3. Set environment variables (optional)
# Create .env.local for local overrides
echo "NEXT_PUBLIC_API_URL=http://localhost:7860" > .env.local

# 4. Run development server
npm run dev

# Server running at http://localhost:3000
```

### Docker Setup

```bash
# Build image
docker build -t enpeak .

# Run container
docker run -p 7860:7860 \
  -e GROQ_API_KEY=your_key \
  -e FIREBASE_CREDENTIALS='{"type":"service_account",...}' \
  enpeak

# Or use docker-compose (if available)
docker-compose up -d
```

### Testing

```bash
# Backend tests
cd backend
pytest tests/ -v

# Frontend tests
cd frontend
npm run test

# E2E tests (if configured)
npm run test:e2e
```

---

## Deployment

### Frontend (Firebase Hosting)

```bash
# 1. Install Firebase CLI
npm install -g firebase-tools

# 2. Login to Firebase
firebase login

# 3. Build production bundle
cd frontend
npm run build

# 4. Deploy to Firebase
npx firebase deploy --only hosting

# Deployment complete!
# URL: https://your-app.web.app (set in NEXT_PUBLIC_APP_URL)
```

**Firebase Configuration (`firebase.json`):**

```json
{
  "hosting": {
    "public": "out",
    "ignore": ["firebase.json", "**/.*", "**/node_modules/**"],
    "rewrites": [
      {
        "source": "/api/**",
        "destination": "https://your-backend.hf.space/api/**"
      },
      {
        "source": "**",
        "destination": "/index.html"
      }
    ]
  }
}
```

### Backend (HuggingFace Spaces)

1. **Create Space**
   - Go to https://huggingface.co/spaces
   - Click "Create new Space"
   - Select "Docker" SDK
   - Set visibility (Public/Private)

2. **Connect Repository**
   - Link GitHub repository
   - Or manually upload files

3. **Configure Environment**
   - Go to Space Settings > Repository secrets
   - Add `GROQ_API_KEY`
   - Add `FIREBASE_CREDENTIALS` (if using Firestore)

4. **Deploy**
   - Push to main branch triggers auto-deploy
   - Or click "Restart Space" manually

**Dockerfile:**

```dockerfile
FROM python:3.11-slim

WORKDIR /app

# Install dependencies
COPY backend/requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application
COPY backend/ ./backend/
COPY data/ ./data/
COPY vectordb/ ./vectordb/

# Expose port
EXPOSE 7860

# Run server
CMD ["python", "-m", "uvicorn", "backend.main:app", "--host", "0.0.0.0", "--port", "7860"]
```

---

## RAG Data Statistics

### Overview

| Metric | Value |
|--------|-------|
| Total Chunks | 5,375 |
| Vector Index Size | ~6 MB |
| Embedding Dimension | 768 |
| Supported Languages | English, Korean |

### Data Distribution

| Type | Count | Description | Source |
|------|-------|-------------|--------|
| vocabulary | 2,661 | A1-C2 level words | Custom generated |
| dialogue | 1,500 | Daily conversations | DialogSum (Apache 2.0) |
| expression | 720 | 16 category phrases | Custom generated |
| idiom | 137 | Common idioms | Custom generated |
| grammar_pattern | 80 | Sentence patterns | Custom generated |
| useful_sentence | 120 | Common sentences | Custom generated |
| scenario_vocabulary | 42 | Scenario keywords | Custom generated |
| sentence_pair | 32 | EN-KO pairs | Tatoeba (CC0) |
| phrasal_verb | 15 | Common phrasal verbs | Custom generated |
| scenario | 14 | Roleplay scenarios | Custom generated |

### CEFR Level Distribution

| Level | Words | Description |
|-------|-------|-------------|
| A1 | 331 | Beginner (basic phrases) |
| A2 | 349 | Elementary (simple sentences) |
| B1 | 448 | Intermediate (main points) |
| B2 | 326 | Upper-intermediate (complex text) |
| C1 | 352 | Advanced (implicit meaning) |
| C2 | 398 | Proficient (near-native) |

### Expression Categories

```
greeting, cafe, restaurant, shopping, transport,
hotel, airport, business, phone, emergency,
opinion, daily, compliment, apology, thanks, request
```

---

## Version

| Component | Version | Release Date |
|-----------|---------|--------------|
| EnPeak App | 1.0.1 | 2026-01-31 |
| Next.js | 14.1.0 | - |
| FastAPI | 0.109.0 | - |
| ChromaDB | 0.4.0 | - |
| React | 18.2.0 | - |
| Python | 3.11+ | - |

---

## License

This project is for educational purposes. See individual data sources for their respective licenses:
- DialogSum: Apache 2.0
- Tatoeba: CC0
- Custom data: Project-specific
